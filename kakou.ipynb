{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kakou = pd.read_csv('kakou.csv', header=None, names=['value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "first = kakou.ix[:1439]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('figure', figsize=(20, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(first.ix[24*4*13:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "def create_dataset(dataset_raw, start, end, look_back=1, test=False):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    ds = np.ravel(scaler.fit_transform(np.array(dataset_raw[:].reshape(-1, 1))), 2)\n",
    "\n",
    "    dataX, dataY, timeIndexY, forwards = [], [], [], []\n",
    "\n",
    "    # 如果指定了起止时间\n",
    "\n",
    "    start_index = start\n",
    "\n",
    "    end_index = end\n",
    "\n",
    "    a = ds[(start_index-look_back):start_index]\n",
    "    \n",
    "    dataX.append(a)\n",
    "    if test:\n",
    "#         dataY.append(ds[start_index:end_index+1, 0])\n",
    "        dataY.append(ds[(start_index-look_back+1):end_index+1])\n",
    "    else:\n",
    "        dataY.append(ds[(start_index-look_back+1):start_index+1])\n",
    "#         dataY.append(ds[start_index:start_index+1])\n",
    "\n",
    "    # 不是构造测试集，并且目标值是填充值，跳过\n",
    "    \n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvX = []\n",
    "cvY = []\n",
    "for i in range(14, 15):\n",
    "    for j in range(24, 80):\n",
    "        x, y = create_dataset(first.value.values, 24*4*i+j, 24*4*i+j, 96)\n",
    "        cvX.append(x)\n",
    "        cvY.append(y)\n",
    "cvX = np.vstack(cvX)\n",
    "cvY = np.vstack(cvY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cvX.shape, cvY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import torch.utils.data as data\n",
    "batch_size = 10\n",
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __getitem__(self, index):#返回的是tensor\n",
    "        x, y = self.x[index], self.y[index]\n",
    "        return x, y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "    \n",
    "cv_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(cvX[:, :], cvY[:, :]), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX = []\n",
    "trainY = []\n",
    "for i in range(1, 13):\n",
    "    for j in range(24, 80):\n",
    "        x, y = create_dataset(first.value.values, 24*4*i+j, 24*4*i+j, 96)\n",
    "        trainX.append(x)\n",
    "        trainY.append(y)\n",
    "trainX = np.vstack(trainX)\n",
    "trainY = np.vstack(trainY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainX.shape, trainY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    MyDataset(trainX[:, :], trainY[:, :]), batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Sequence(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(Sequence, self).__init__()\n",
    "        self.hidden_dim = 51\n",
    "        self.input_dim = input_dim\n",
    "        self.lstm1 = nn.LSTMCell(input_dim, self.hidden_dim)\n",
    "        self.lstm2 = nn.LSTMCell(self.hidden_dim, input_dim)\n",
    "        self.hidden2out = nn.Linear(input_dim, 1)\n",
    "\n",
    "    def forward(self, input, future = 0):\n",
    "        outputs = []\n",
    "        h_t = Variable(torch.zeros(input.size(0), self.hidden_dim).double(), requires_grad=False)\n",
    "        c_t = Variable(torch.zeros(input.size(0), self.hidden_dim).double(), requires_grad=False)\n",
    "        h_t2 = Variable(torch.zeros(input.size(0), self.input_dim).double(), requires_grad=False)\n",
    "        c_t2 = Variable(torch.zeros(input.size(0), self.input_dim).double(), requires_grad=False)\n",
    "#         pdb.set_trace()\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "#             pdb.set_trace()\n",
    "            h_t, c_t = self.lstm1(input_t, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(c_t, (h_t2, c_t2))\n",
    "#             out = self.hidden2out(c_t2)\n",
    "            out = c_t2\n",
    "            outputs += [out]\n",
    "#             pdb.set_trace()\n",
    "        for i in range(future):# if we should predict the future\n",
    "            h_t, c_t = self.lstm1(c_t2, (h_t, c_t))\n",
    "            h_t2, c_t2 = self.lstm2(c_t, (h_t2, c_t2))\n",
    "#             out = self.hidden2out(c_t2)\n",
    "            out = c_t2\n",
    "            outputs += [out]\n",
    "#         pdb.set_trace()\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "seq = Sequence(1)\n",
    "seq.double()\n",
    "criterion = nn.MSELoss()\n",
    "# use LBFGS as optimizer since we can load the whole data to train\n",
    "optimizer = optim.RMSprop(seq.parameters(), lr = 1e-3)\n",
    "# optimizer = optim.LBFGS(seq.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "losses = []\n",
    "for epoch in range(num_epochs):\n",
    "    print('Starting epoch %d / %d' % (epoch + 1, num_epochs))\n",
    "    for t, (x, y) in enumerate(train_loader):\n",
    "        x_var = Variable(x).double()\n",
    "#             x_var = Variable(torch.randn(30, batch_size, len(feature_selected)))\n",
    "#             print x_var.type\n",
    "        y_var = Variable(y).double()\n",
    "#             pdb.set_trace()\n",
    "        def closure():\n",
    "            optimizer.zero_grad()\n",
    "#             output = seq(x_var, y_var.size(1))\n",
    "            output = seq(x_var)\n",
    "#         loss = criterion(output[:, :2], y_var[:, :2])\n",
    "#             weight = Variable(torch.log(torch.arange(output.size(1) + 1, 1, -1))).view(1, -1)\n",
    "            weight = Variable(torch.ones(1, output.size(1)))\n",
    "#             pdb.set_trace()\n",
    "            mse = torch.pow(output - y_var, 2)\n",
    "#             loss = torch.sum(mse * weight.double().expand_as(mse))\n",
    "            loss = criterion(output, y_var)\n",
    "            losses.append(loss.data.numpy()[0])\n",
    "#             print('loss:', loss.data.numpy()[0])\n",
    "            loss.backward()\n",
    "#             pdb.set_trace()\n",
    "#             print seq.lstm1.weight_hh.grad\n",
    "            return loss\n",
    "        optimizer.step(closure)\n",
    "plt.plot(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result = []\n",
    "for (cvx, cvy) in cv_loader:\n",
    "        x_var = Variable(cvx).double()\n",
    "        y_var = Variable(cvy).double()\n",
    "        output = seq(x_var)\n",
    "        result.append(output.data.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.vstack(result).shape, cvY.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def mape(ypredict, ytrue):\n",
    "    return np.mean(np.abs(ypredict - ytrue) / ytrue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mape(np.vstack(result)[:, -1], cvY[:, -1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(np.ravel(cvY[:, -1]))\n",
    "plt.plot(np.ravel(np.vstack(result)[:, -1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
